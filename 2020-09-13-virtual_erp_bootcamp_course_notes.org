:PROPERTIES:
:ID:       20210627T195239.031778
:END:
#+TITLE: Virtual ERP bootcamp - course notes

* Course Notes
*** Chapter 1 - introduction :ankified:
***** an Event Related Potential is an electrical potential (=voltage) that's related to a specific event during an experiment. A marker describing the event is put onto the raw EEG data (can signify a stimulus, a behavioral response, eye movement etc.)
***** there are many restiriction - must keep humility
*** Chapter 2 - ERP basics :ankified:
***** EEG basics
******* gel to connect between electrode and skin
******* electrode connected to amplifier
******* Y axis is voltage n micro-volts
******* HZ = number of peaks per second
******* the different frequency bands:

              - delta: 1 - 3 hz
                + sleep
              - theta: 4 - 7 hz
              - alpha: 8 -  12 hz
                + awake but zoned out, introspection
              - beta: 12 - 30 hz
                + smaller and less regular, menatally active
              - gamma: 30 + hz
                + small and quick, more related to internal feedback loop

***** Extracting ERPs
******* simulation computer sends signals to EEG-recording  computer to mark the exact time of stimulus presentation
******* signal averaging
********* give stimulus several times
********* divide EEG into epics of activity, after each stimulus. all same length of time: 200-2000ms
********* line them up and average the values per timestamp
********* only activity that is consistent between all epics will show up in the resulting average - while activity that's unrelated to the stimulus we want to test will be averaged  out.
******* great temporal resolution. nearly real-time.
******* poor spacial resolution
******* stimulus-locked average (time_0 is stimulus onset)
******* response-locked average
******* both are useful, since there's a lot of variability in reponse time - this muddles out the respons data if using stimulus-locked avg., and vice versa - muddling the data about activity immediately after the stimulus in response-locked avg.
***** Example N170
******* N = negative, P = positive. the number is the time in ms.
******* to get an overall sense of the data, can use a "grand average" - avg. over the waveform responses of all subjects.
******* do we have a specialized brain area for perceiving faces, or do we use the same area for anything that we're expert in perceiving
******* to test the hypothesis that N170 is caused by expertise they tested two groups of subjects that are experts in their fields: birds and dogs, and showed both groups pictures of both dogs and cats.
******* they expected dog experts to have a bigger N170 when viewing dogs than when viewing cats, and vice versa for cat experts - and so it was.
******* it's meaningful to have both directions tested since this rules out the possibility that the actual stimuli used were somehow stronger for (e.g.) birds than for dogs - by showing the reverse effect for the reversed condition.
***** Signal-to-noise ratio
******* noise - uncontrolled variation in the signal at the time of interest
******* how many trials do we need to get an acceptable STNR?
******* oddball stimuli = showing two types of stimuli, where one is much rarer than the other (the oddball)
******* use pre-stimulus recording to estimate noise
******* STNR grows only like the sqrt of the number of trials.

we need to x4 the trials to get data that's x2 as clean.

***** Sources of noise
******* other brain activity unrelated to the stimulus e.g. alpha band oscillations while on a task.
******* biological artifacts - eye movement, skin, muscles of the neck and head.
******* induced electrical activity from the equipment - electrical current->magnetic field->electric field (voltage changes)
***** conventions for electrode placement
******* the international 10/20 system - 10%-20% of total distance between electrodes
********* nowadays: 5%-10%
********* naming, from front to back:

                        - Fp - frontal pole
                        - F   -  frontal
                        - C   -  central
                        - P   -  parietal
                        - O   -  occipital
                        - T   -  temporal
                and combinations of the above for in-between areas.

********* numbering:

- left - odd numbers
- right - even numbers
- middle - z for zero

******* geodesic arrangement
********* guarantees equal distance between each electrode
********* numbering is idiosyncratic, i.e. unique per article, and a reference to the international system is given.
***** conventions for showing the recorded data
******* usually recordings from adjacent electrodes are very similar so there's no point in showing all of them
******* usually show data from one or two electrode in the relevant area, and show scalp maps to demonstrate the propagation of the signal in time

[[/mnt/c/Users/Jonathan/Google Drive/.notes/associated_images/scalp maps.png]]

******* usually don't show data from every subjet - rather use the "grand avgerage" from all subjects
******* plotting negative-up is an outdated convention, but it's still used sometimes, so watch out for it
*** Chapter 3 - ERP components :ankified:
***** Overview
******* peak != component
******* peaks in the recording are the results of brain components - which we cannot observe directly
******* how are ERPs generated?
********* generated by cortical pyramidal cells during transmission
********* a large number of neurons must be active at the same time in order fore their combined activity to show on the surface.
********* the transmission/passage of electrical current along neurons produces an electrical field outside of the neuron's body, and these fields, created by many neurons are accumulated.
********* this creates an *equivalent current dipole* that points perpendicular to the active cortical surface.
******* essentially, an ERP *component* is the sum of activity of a cluster of functionally related neurons, measured as the extra-cellular voltage created by their activity.
******* components overlap in time, and the peaks in the ERP are the combined effect of many components.
******* voltages in a conductor (the brain) sum together - the voltage measured in an electrode is the weighted sum of the voltages at the source components (weighted by the distance from the electrode, the direction of the dipol and the conductivity of the brain and scalp)
******* there are many more components than peaks.
******* the relationship between the peak and the underlying components is complex
***** naming conventions - peaks and components
******* the numbers may represent the ordinal place of the peak since the reference time (stimulus/response)
******* P = positive, N = negative - *direction*, not absolute value in volts.
******* the very first peak is named C since it can be either positive or negative depending on whether the visual stimulus is displayed above or below the fixation point.
********* the peak comes from the initial visual response from the visual cortex, and the difference in polarity is due to the fact the the cortex is folded over in that area, and the matching area for processing either kind of stimulus are on either side of the fold
******* the same peak number in  different contexts will often not refer to the same underlying phenomenon
******* sometimes, a specific name, e.g. N400, will be used a reference to a specific response that's considered to be well known - but note that that response may actually occur at  a much later time in a specific contex (e.g. later in the context of a harder task)
***** common ERP components
******* sensory components
********* visual sensory responses
*********** C1 as discussed above

will not show unless the stimulus is in the upper half of the visual field,
since it will otherwise merge with the P1 peak.

*********** P1 and N1 are also related mostly to higher level functions of the visual cortex.
*********** these first peaks are highly sensitive to the nature of the stimulus - both in terms of physicality (e.g. brightness) and in terms of contents (e.g. faces, text)
*********** larger for attended areas.
*********** start ~50ms
********* auditory sensory responses
*********** much faster than visual responses ~1ms
*********** initial ERPs come from the [[file:2020-05-27-brainstem.org][Brainstem]] (not the pyramidal neurons of the cortex!)
*********** short- medium- and long-latency responses
*********** MMN = MisMatch Negativity response - is a stronger negative response to the oddball stimulus than to the prevailing one.

- it's useful for studying subjects like comma patients' schizophrenics and babies,
since it's not task dependent
- the less frequent the oddball - the stronger the res response. same as P300

******* attention
********* covert attention - internal process of changing the focus of our attention.
********* in visual stimuli - using our peripheral vision, and choosing mentally what to focus on.
********* seen in the N2PC component.
********* visual field - contra lateral
******* working memory
********* CDA - Contralateral Delay Activity, also a negative component like N2PC, related to images being retained in short term memory
********* it's possible to use ML to decode a face (out of a given set of known faces) from the ERP of seeing and *remembering* them (even after the faces have disappeared) - only works with ~40% accuracy
******* language
********* N400 - different, stronger response for incongruous words, those that are unpredictable
********* P600 - a response to  unpredictable grammatical mistakes
******* categorization
********* P300 (=P3) - when subjects are required to categorize stimuli, such ass the oddball paradigm
********* the amplitude of the P3 is greater the rarer the stimulus. (i.e. it's inversely proportional to the probability of the appearance of the stimulus)
********* the "stimulus probability" is not the probability of the stimulus per se, but the probability of any of the stimuli that make up a specific category.
******* emotion
********* arousal: activating - deactivating
********* valance: pleasant - unpleasant
********* LPP - late positive potential. similar scalp distribution to P300, may be the same may be not.
*** Chapter 4 - Generation and propagation of ERPs :ankified:
***** from source to scalp - intro:
******* ERPs are due to *post* synaptic potentials - they show the inputs, /not/ the outputs, to a neuron
******* mostly come from pyramidal cells
******* pyramidal cells are mostly aligned perpendicular to the surface of the cortex
******* the cortex is really folded, so they're *not* perpendicular to the scalp
******* how a voltage is created around cells:

              1. excitatory NT(Neurotransmitter) released into the synaptic gap at the apical (=top) dendrites
              2. this causes inflow of positive ions (which?) into the dendrites - creating a negative charge around the dendrites
              3. for reasons of electrical equilibrium (but how?) this causes net positive charge around the cell body.
              4. which causes a dipole near the cell - in the direction (- to +) from the scalp down towards the white matter.

******* and the opposite direction for inhibitory NTs
******* this can work because pyramidal cells are parallel - their dipoles sum up.
******* can't get an ERP from areas where the cells are connected in many directions - they would sum to 0.
******* the Equivalent Current Dipole is the vectore sum of all dipoles - that's why the negativity or postivity of the dipole is *not* an indication of whether there's an excitatory or inhibitory response underneath.
******* ERP is actually real-time
******* there's always an inverse voltage on the other side of the scalp
******* voltages spread out as they travel, the resistance of the scalp distributes them even further
***** Estimating source location and waveform
******* there's a problem - there are many sources, but we record a single superposition of their signals
******* two approaches:
********* clever experiment design + careful analysis
********* mathematical analysis (i.e. source-localization)
*********** recall that source signals are weighted into the final observable signal.
*********** we want to find, given the final signal, the various sources that created it - infinite solutions
*********** not enough data as it is - we need to add constraints to narrow down
******* MEG in comparison gives better spatial resolution to begin with
********* because  the scalp is transparent to magnetism, while having a high resistance to electrical current.
********* much more expensive than EEG
***** source localization techniques
******* use equivalent current dipole measure
******* assumes there's a small number  of sources
******* iterative approach

            - not much used today - very sensitive to individual researcher assumptions
            - start with a model assuming locations and amplitudes of signals
            - calculate the model-driven final signal
            - compare to true signal and correct model, across time points.
            - very much like back propagation

******* distributed source approach
********* based on the weighted average idea
********* tessellate the brain using structural MRI
********* assume each surface is a tiny dipole, directed perpendicular to the surface
********* just need to determine the magnitude of the signal from each patch at any point in time.

                we know the location of each source, and the locations of the electrodes, so we can estimate the weight based on the distance

********* a set of equations based on the sum in each electrode:

                    $E = W \cdot S $
                    $S = W^(-1) \cdot E$

********* the solution gives the magnitude at each source
********* problem: the weight matrix is generally non-invertible!
********* solution: use a pseudo inverse. requires adding constraints:
*********** minimum norm: use solution with overall lowest activation
*********** LORETA: use solution with maximum smoothness of activation magnitudes between neighboring patches.
********* another problem: we have no way to know how far these assumptions take us from the truth. there's no estimate of their accuracy.
********* we _can_ use this method to show that a certain activation pattern is _consistent_  with the result we got - even if there are other possible options.
******* Bayesian approach - giving the a posterior probabilities of the magnitudes given the observed signal at the scalp
********* not used very much
******* generally - ERP is not very good for making localization claims! much stronger for temporal claims
***** wave difference techniques - finding components
******* how can we isolate a specific component out of the sum of signals that's actually measured at the electrode?
******* target - standard
********* example:  probability-sensitive P3 wave (oddball): take the oddball response and subtract the standard (=non-oddball) response
******* generally if we want to examine the activity related to a specific stimulus, we need to design an experiment where this activity would be (as accurately as possible) the difference between the wave response of two other cases.
******* for example: to test the reponse to faces kuefner et al. showed subjects images of faces, and scrambled images of faces - the difference between them is just the response to face vs. not-face - removing all of the shared responses to (most) anything else (the environment, the color of the image etc.)
*** Chapter 5 - what ERPs are especially suited for :ankified:
***** ERPs give a *continuous* measure of the brain's response - in ms resolution
***** so we can measure what happens between the stimulus and the response.
***** ERP latency
******* rare-frequent difference wave can be used for assessing the time of categorization
******* oddball with women's vs men's names
******* same as above - we can deduce that by the time we see a difference in amplitude between two stimuli, it means the brain has started to tell the difference
******* alternatively  - by the time the difference wave deviates from zero.
******* dimming the stimuli - delay everything that follows
******* possible to delay categorization by making the test more demanding - like counting the letters - odd/even
******* the time it takes for the P3 peak to arrive - referred to here as the latency - becomes later as the classification is "harder" and takes more time in itself (duh)
******* in N2PC experiments - there's a greater negativity in the hemisphere that's contralteral to where the target is
******* LRP = lateral readiness potential
******* same as N2PC - contralteral negativity
******* looking at conta - ipsi difference wave: we know that the contra is stronger than the ipsi response, so when the difference wave crosses zero is a good estimate to when the brain has begun to prepare for a motor action.
***** Example from schizophrenia:
******* cognitive impairments actually more meaningful for recovery/development of the schizophrenia than positive symptoms such as hallucinations
******* significantly lower P3 (oddball) response in schizophrenics than normal
******* also ~70ms slower response time (=behavioral)
******* but! the peak of P3 is at the same time, not slower
******* rare-frequent (wave difference approach) will be start to be positive just after the brain starts to respond differently to the stimulus - just when it understands  that the stimulus is in fact the rare one.
******* the delay in response, lower P3, and P3 timing were all seen both for oddball and standard stimuli
******* rare-frequent turn out to be the same for both groups.
******* from this they deduced that the processing and categorization of the stimulus is not affected in schizophrenics, and that the delayed response must be caused by something that happens later on - maybe in response preparation or execution. and indeed they found something else in another study.
*** Chapter 6 - general technical aspects :ankified:
***** Fourier analysis
******* represent any waveform as a sum of sinusoids :ankified:
******* it's possible to *perfectly* reproduce a given EEG signal as composition of sinusoids :ankified:
******* a Fourier transform is the mathematical operation of finding out how to deconstruct a given signal into sinusoids. :ankified:
******* EEG signal is in the time domain (it's a amplitude of the signal/time graph) :ankified:
******* the transform brings us to the frequency domain - which shows what's the amplitude we need for the sinusoide components of any given frequency :ankified:
******* there's a unique solution!
*********** the transform gives the phase for each sinusoide as well - but generally don't need it much
******* key observations #1: a given sinusoid in the deconstruction *does not* mean that anything in the original signal/source is actually oscillating at that frequency
***** filtering
******* low pass filter
********* lets low frequency through
********* cleans out noise from surrounding electrical fields etc.
********* usually filter out at ~30Hz
******* high pass filters
********* used to block gradual drifts that arise from skin potential etc.
******* band pass filters
********* combines the above two
******* notch filter
********* like a very narrow, reveresed band pass - used for blocking out specific frequencies.
******* filters are described in the frequency domain: gain -frequency graphs. (gain = multiplication factor for attenuating the frequecny)
******* filters are often referred to according to the frequency at which attenuation hits 50% = "half-amplitude cutoff"
******* another way is to refer to the rolloff - how quickly attenuation happens.
********* take the steepest part of the slope.
********* slow rolloff is good - sharp rolloff can cause distortions in the frequency domain
******* order of events in analysis:

              1. transform signal to frequency domain
              2. see where there are peaks etc.
              3. choose and apply a filter
              4. use the revers-fourier transform to get the new clean signal.

********* Q. why does the lowpass filter in the example also smooths out the low frequencies?
********* A. it does - what it doesn't smooth out is the peaks in the low end of the *frequency domain* graph
******* Key observation #2:  filters are a controlled form of distortion, if you apply them to strongly you lose precision in the time domain - and worse - you can absolute bogus, artificial results.
******* important to check filter values when reading a paper!
********* safe values for high pass filters: <= 0.1 Hz
********* safe values for low pass filters: => 20 Hz
********* unsafe values for high pass filters: > 0.5 Hz
********* unsafe values for low pass filters: < 10 Hz
***** time-frequency analysis
******* when looking at stimulus-locked averages, responses that do in fact exist may get averaged out when theyre not in the same phase in relation to the stimulus in all subjects
******* frequency domain analysis doesn't show us any information about time at all.
******* in time-frequency analysis we use wavelets (~500ms) instead of infinite sine waves
******* each wavelet thus has the frequency and amplitude it had before, but also a time where it fits into the overall sum
******* we want to transfer the data from all subjects into the time-frequency domain, and only then average it.
******* in these 2D graphs, the color represents the amplitude.
******* since the wavelets are not negative or positive like the time-domain response, they don't cancel each other out.
******* since each wavelet in the resulting graph is "smeared" over 500ms, we lose quite a lot of the temporal resolution we would otherwise have - but this allows us to see responses that would otherwise  have been completely lost.
******* Note! [[id:905c942d-acdf-44c8-acf2-0f07c38237d6][key observations #1]] still holds true here
******* it's not trivial to tell from the time-frequency graph whether there are actual oscilations (=peaks) at a given time.
******* a rule of thumb is that narrow bands of power (= small range of frequencies sustained over a long period of time) mean actual oscillations in the the signal.
***** baseline correction
******* Typical epochs extracted as ERP signals lat from ~200ms before stimulus to ~800ms  after it. (1 sec in total)
******* there are great variations in voltage over time due to factors unrelated to the brain, much larger than the typical response voltage. these can change the actual - measured - voltage from stimulus to stimulus in the same experiment.
******* we'd like to use the 200ms prior to each stimulus to normalize that entire epoch - detract that average from the entire epoch's signal.
******* the first 200ms will hover around 0 uV
******* problem: it's not actually guranteed that those 200ms are free from interference (e.g. overlap of the response from the previous stimulus, or any random one-off noise)
******* we have to check carefully how the pre-stimulus signal looks like
******* problem: even if the pre-stimulus signal is flat, it may still be an overlap - just a longert one...
******* overlap
********* sometimes it's not a problem ("non-differential overlap"): if the two conditions we're comparing are presented in random order, then on average the overlap  will be the same for both -> the correction will be the same for both -> any difference between the two cannot be explained by the correction, only by an actual difference.
********* sometimes it is ("differential ovelap"): if not all epochs have the same amount of overlap, than the above doesn't hold, and the different correction applied to two epochs bekonging to the same condition will make them appear different.
********* as a rule of thumb, if the timing of the stimuli is fixed, and the condition order is well randomized - it's usually ok.
*** Chapter 7 - recording and analysis methods, steps, reading a paper
***** Recording steps and considerations
******* number of participants: should be ~15-20 for within group comparison
******* test the monitor's delay (from computer sending the signal to the screen displaying it) and add that to the "stimulus onset" time the computer reports
******* how many electrodes do you need?
********* usually 12 minimum
********* usually 64 maximum
******* "active" electrodes have a built-in pre amp, and result in better data quality
******* digitizing the EEG signal. an ADC (=analog to digital converter) samples the raw EEG output into digital, discreet, data.
******* sample rate:
********* at least 2x the highest frequency present in the data (in the frequency domain?)
*********** otherwise we get aliasing - to avoid that, use  a low-pass filter, to remove the high frequencies prior to digitizing
********* 250Hz-1000Hz (=samples/second) for cognitive/affective studies
********* ~10K Hz for sensory studies
******* electrode impedance: the extent to which the electrical current from the the living cells in the skin tissue is impeded (=delayed, made less) on its way to the electrode
******* impeded by the epidermis and sebum
******* impedance *doesn't* reduce the amplitude of the signal. it *does* add low frequency noise.
******* Reference and Ground
********* there's no such thing as the voltage *at* an electrode, only between electrodes.
********* it is however useful to define the *absolute* voltage at an electrode the potential difference between that electrode and the rest of the brain.
********* we always measure the voltage between a given Active electrode (i.e. electrodes in any of the sites on the scalp), and two other (fixed) electrodes: Ground, and Reference
********* we then calculate the voltage between the Active electrode and the Reference electrode as  (A - G) - (R - G).
********* the location of Ground is unimportant, as it's being calculated out.
********* the location of the Reference is vitally important: any activity there will enter the recorded data, since we're in fact measuring (or referring to) the potential difference between the Active and the Reference locations.
*********** it's so important that different choices of reference can give reverse polarity of activity for the same Active electrode(!)
********* there isn't an ideal reference location - but using the mastoids (behind each ear, and averaging the two) is a customary approach
********* using a subtraction like this gives a cleaner signal than using Ground directly
********* so, in fact - the voltage we record at any electrode is not just the activity at that electrode, but always that activity - activity at the reference site
******* common artifacts
********* EOG - Electrooculogram
*********** there's an electrical dipole between the front of the eyeball (cornea, positive) and the back (retina, negative)
*********** this is strong enough to affect the voltage measured at the scalp - ~30 micro-volts at the frontal electrodes.
*********** it can also be used to measure blinking and eye movements during the experiment:
************* by looking at electrodes above and below the eye (VEOG - Vertical EOG), and at the temples (Horizontal - HEOG)
************* Note! both of these measures show very little brain activity - it's being subtracted out.
************* _for blinks_, there's a positive peak in electrodes above the eyes, and a negative peak in electrodes below the eyes. using a bipolar VEOG signal ( VEOG_lower - VEOG_upper) will give a strong negative peak, making the blink more pronounced
************* _for up-down movements_, use a bipolar VEOG signal: when the eyes are turned upwards you get a positive voltage above and a negative below, and vice-versa
*************** _for left-right movements_, use a bipolar HEOG signal: when the eyes are turned to the left we get  a positive voltage on the left, and a negative on the right and vice-versa
********* EMG - Electromyogram
*********** voltage changes caused by muscle contractions (forehead, neck, jaw etc.)
*********** also if the subject just moves around in the chair or whatever - this makes it hard to record ERPs in natural environments, although it *is* being done nowadays
********* the voltages from the above (esp. eye movements) can really change the way a response ERP will look like, esp. for visual stimuli
******* artifact rejection and correction
********* how to avoid?
*********** ask subjects not to move/blink only at certain times/use eye tracking to ensure they keep fixation etc.
********* throw out (reject) trials with artifacts
********* estimate the artifact's influence and subtract it from the signal.
********* How?
*********** using ICA (Independent Component Analysis)
*********** it's the most common algorithm for correcting artifacts
*********** it's pretty good for blinks and eye movements, but be suspicious of use for other artifacts.
***** Analysis steps conclusion:

            1. choose  reference location(s)
            2. set a lowpass filter and matching sampling rate
            3. record and subtract ground
            4. optional - downsample data to make analysis faster
            5. highpass filter to remove slow wave artifacts
            6. scan for other artifacts, discard and/or correct them with ICA
            7. extract ERP epochs, time locked to the stimulus (or to the response)
            8. average the relevant ERPs and/or perform time-frequency analysis etc.
            9. analyze the results using [[file:2020-09-07-anova.org][ANOVA]] or similar

***** Choosing time windows and electrode sites
******* bogus-but-significant = type 1 error = false positive
******* idealy - we want to choose the time window and electrode sitres that we refer to in analysis *before* we look at the data, so we're replicating the common practice in the field, and not zoomin in on some artifact in out experiment.
*** Chapter 8 - reading a paper
***** but how can we make new discoveries this way? why can't we also let the data talk?
***** TODO read "how to get statistically significant effects in any ERP experiment (and why shouldn't)" by steven luck  et al.
***** Baseline problems:
******* check the slope of the baseline! - if two conditions have a different slope it will skew the analysis
******* this skew will be noticable as an effect starting close to time 0, and lasting for a long time.
******* the problem will likely be in the design of the experiment - check the methods.
***** Eye movement:
******* lateral eye movements create lateral effects: more negative voltage contralateral to the direction of movement.
***** analysis problems:
******* using the peak voltage to assess the size of the effect
******* unjustified time window and/or electrode sites - without repeated experiments to rule out that the effect is a false positive.
***** "To avois physical stimulus confounds, use identical stimuli accross conditions, and vary only the instruction"
***** The above requires that the constant stimulus will contain more than one point of interest, so that we can instruct subjects to attend to one or the other in different blocks.
***** The above is not always possible (for example when studying words)
