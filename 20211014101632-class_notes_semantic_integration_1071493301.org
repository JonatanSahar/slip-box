:PROPERTIES:
:ID:       20211014T101634.69752    4
:END:
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+title: Class notes: Semantic integration (1071493301)
*  Class notes: Semantic integration (1071493301)
*** intro
***** 80% final rxam in english - home exam!
- integrative questions - need to understand the course, not memorize
- 2o  active reading each week - 1-2 paragraphs with comments:
    send to mudrikli@taux.ta.ac.il - *latest on tuesday night!*
      1. Take home message from the paper + justification
      2. Questions/comments/ideas for experiments.
*** 14.10.21
***** concepts
- words for representing the impressions of the world on our souls (aristo)
- mental representations of classes of things (murphy 2004)
- the cornerstone of cognition?
  - possible to recombine them with one of another
  - stimulus independent
***** Semantic knowledge:
- knowledge about relations between different concepts, words, precepts
- we deal with relations between concepts
***** semantic categories:
- the category size affects the speed with which people categorize objects (peacock is bird vs animal)
- typicality  - slower to categorize atypical examples
  :ID:       20211021T184206.487470
  :END:
- slower to transfer knowledge about members of a category from typical to very atypical, and no transfer from atypical to typical
  :ID:       20211021T184410.976028
  :END:
- hirearchy of concepts
- separation vs inclusion
- concept cells (jennifer aniston)
***** Theortical models
******* spreading activation - nodes of connected concepts, activating a concepts causes the activation of its neighbors
- relations are formed by associations
- asymetrical, activation has a direction (butterfly-insect, flea-dog)
- the associations index temporal congruity or co-oocurance in language
******* distributed models:
- objects are defined by their properties in any of many different dimensions of their attributes (taste, shape, color)
- relation is decided by feature ovelap
- what is the basic unit of concepts? Is it an object or an attribute of an object?
***** Semantic relations
******* different types of 1st (spatial, temoral, function, semantic) and also 2nd order relations (relations between relations)
******* different types of semantic relations:
- Abstract
- associative
***** critiquing a paper:
- how does the experiment push us (the subjects) towards acting in a way that confirms one model over the another
*****
*** 21.10.21
+ comparing nonsense objects to noise: we are activating a whole bunch of cognitive processes that are not necessarily what we want to measure (greater attention, surprise, etc.)
+ generally true of comparisons - always think what types of activity are activated!
+ dorsal and ventral streams of visual processing
  - ventral - what
        or: vision for perception
  - dorsal - where, actually how (we can we use it)
        or: vision for action
  - D.F patient with slit experiment - entering a card into the slit vs estimating it. Ventral lesion.
  - perceiving and acting on objects are dissociated
  - more differences: see slides
    - memory: procedural memory/stable affordances are actually though to be located in the ventral stream
    - consciousness: high/low meaning how much it tends to enter consciousness
+ conclusions in papers are always a sort of narrative - the authors choose what the results may mean. For example, relying on "known" functions of brain areas - most areas have many different functions shown in different papers.
+ embodiement - the idea that representations of meaning rely on sensory-motor areas
  :ID:       20211021T183944.751050
  :END:

 * paper - martin et al 1996
***** bottom line:
- brain areas that are involved in using tools, and in thinking about the actions they preform are involved in perceiving and recognizing them.
- naming animals requires reactivating primary visual areas in order to differentiate between highly similar object
***** justification:
- areas in the premotor cortex that are active when imagining grasping tools were active when subjects recognized tools, but not animals
- areas in the middle temporal gyrus, active when listing action words that are connected with objects, were also active when subjects recognized tools, but not animals
- activity patterns shown both in comparison to nonsense objects and directly compared to animals
***** my take:
    The main message of the paper is that brain areas which are involved in using tools, and in thinking about the actions they preform are also involved/activated in perceiving and recognizing them. This is substantiated by comparing the brain activation  of subjects while they were identifying drawings of tools vs drawings of animals, comparing both conditions also to a control condition of viewing nonsense tools. The comparison showed that areas which activated deferentially while identifying tools were the same, to a large degree, as those found to be involved in both imagined grasping (in the premotor cortex), and in naming action words related to objects (in the middle temporal gyrus)
    Another finding is that naming animals requires reactivating primary visual areas, possibly because of the increased difficulty in differentiating highly similar/nuanced shapes. This was substantiated to some degree by comparing both animal drawings and silhouettes to tools, in order to eliminate the possibility that the heightened activity in V1 is due to the high visual complexity of animal shapes.

    For future research I think it would be interesting to test the same idea using drawings of fruits and vegetables - since they are non-functional, and have a rich semantic context but have simpler shapes and are more easily distinguishable than animals. It will be interesting to compare the brain activation with tasks of describing the appearance of a fruit, describing its taste, and with recalling its taste without describing it. It will also give more information regarding the hypothesis about the reactivation of the visual cortex.
    I think it would have been more informative to have scans of subjects imagining operating tools rather than just grasping - but in some sense this is actually a stronger result, showing that the connection with motor information is so strong that it doesn't require specificity to be significant.

*** 28.10.21
***** Mirror neurons
- motor cortex neurons are activated when we see another's action - and this is helps us to understand it.
- active first of all when er actually perform the action
- encode the combination of the motor action (which body parts move, and how), and its function - they don't respond to actions that look like a real meaningful action, but without the meaning (like "lifting" nothing)
- some mirror neurons respons depending on the perspective
  - first person, 3rd person from the front, and 3rd person from the side - elicit responses from different neurons
***** three main claims of embodiement theory: see slides
***** TMS experiment:
******* give TMS to excite left or right hemisphere
******* activation "creates" shorter RT for understating hand-related action words
***** Caramazza's criticism
- are mirror neurons motor? They respond to observation as well, and some of them respond only to observation.
- the mirror neurons' activation may be in fact caused by the representation of the action, which is "higher" or different, and not because the mirror neurons themselves encode the meaning/representation
- also from Caramazza - regular pliers and reverse pliers create the same response: are mirror neurons really motor? This seems to imply that they encode just the meaning of the action (picking something up)
- wen need to be very critical of the interpretive act that is always present when we explain the meaning of data
***** paper - Aziz et al 2006
***** Summary
- This paper is trying to show that mirror neurons are part of the brain representation of semantics/conceptual knowledge.
  They had participants watch clips of actions performed with different body parts
  (mouth, hand and foot), and read phrases describing such actions.
  They found matching brain activity in both tasks: they defined areas of peak activity for each body part during the observation task, and found significantly higher activity in those areas during the reading task of the matching body part.
- reading/linguistic use involves the "re-enactment" of the actions being read.  (according to them)
- the transfer of information through language (would be faster) if the same brain activity that underlies the actual - experienced - meaning would underlie the use/comprehension of the language referring to that meaning. In this case - the meaning of an action is felt "through" activity of the mirror neurons, so it would make sense for the same neurons to be involved in comprehension of action words. (according to them)
- also (according to them) it makes sense for the way that we intuitively understand the actions of others (=mirror neurons) to be related to (or use the same underlying representations as) the way we explicitly understand them (language).
- basically, they say that language is used to convey an already-existing meaning which is understood or experienced directly as a "felt sense", and so it makes sense for semantic language processing to rely on the same representations as this direct experience.
- they claim neither motor imagery, nor covert speech (in observing task) are the cause for the similar activation: if there was covert speech there would be more activation of the L hemisphere in the observing task, and if it was imagery there would have been more bilateral activation in the reading task.
***** critique
      - activation during observation could be subjects being reminded of the sentences they read
      - could be that reading about someone preforming an action triggers the same kind of kinesthetic empathy response as watching them actually move - so this and mirror neurons are two aspects of the same empathy-related phenomenon rather than the same semantic knowledge.
        - to further test - we can compare phrases describing someone specific doing the action, phrases where "I" am doing the action, and phrases describing the action in impersonal terms. If the activation is related more to semantics, we expect not to see a big difference bet
***** my take:
The authors if this paper are trying to show that mirror neurons are part of the brain representation of semantics/conceptual knowledge.
They had participants watch clips of actions performed with different body parts
(mouth, hand and foot), and read phrases describing such actions, and they found matching brain activity in both tasks: they defined areas of peak activity for each body part during the observation task, and found significantly higher activity in those areas during the reading task of the matching body part.

They make interesting points about linguistic use involving the "re-enactment" of the actions being read. First they make an argument for the speed of processing, saying that the transfer of information through language would be faster if the same brain activity that underlies the actual - experienced - meaning would underlie the use/comprehension of the language referring to that meaning. In this case - the meaning of an action is felt "through" activity of the mirror neurons, so it would make sense for the same neurons to be involved in comprehension of action words.
Also, it makes sense for the way that we intuitively understand the actions of others (=mirror neurons) to be related to (or use the same underlying representations as) the way we explicitly understand them (language)   .
Basically, they say that language is used to convey an already-existing meaning which is understood or experienced directly as a "felt sense" of some kind, and so it makes sense for semantic language processing to rely on the same representations as this direct experience.

A couple of possible confounds I can think of, are (1) that activation during observation could be due to subjects being reminded of the sentences they read, so that part of the effect is reactivation of the memory, and also, (2) that it's possible that reading about someone preforming an action triggers the same kind of kinesthetic empathy response as watching them actually move - so this and mirror neurons are two aspects of the same empathy-related phenomenon rather than the same semantic knowledge.
To further test the last point - we can compare the reading of phrases describing: (i) someone specific doing the action, (ii) first person (I am) doing the action, and (iii) the action in impersonal terms.
If the activation is related more to semantics, we'll expect not to see a big difference between these conditions.
***** from class
******* results:
********* horizontal slice - because they're interested in the different activations along the sensory&motor cortices.
********* double dipping: using the same data to define the ROI and analyze what happens in them
********* they're not doing double dipping here - they're defining the ROIs base on clips, and analyze on the sentences
********* look at the graphs and try to see what you don't understand - and doesn't sit with the main claim
*** 4.11.21
***** "space and time in the human brain" - paper to read
***** is perception actually different from representation, is the latter acting on the former, or are they actually the same in some way? Liad thinks that they are two aspects of the same, or work in unison, that our experience is some combination of the two.
***** Liad's PhD: the change in the order of drawing conclusions:
******* now we try to say - let's check how the brain works, and deduce from it how the mind must work
******* the old way - we know how the mind/cognitive processes work, then there must be a place in the brain that works like that, let's find it!
***** whenever the writers declare something (like "this way is less flexible than the other") - think if you agree with it
*** 18.11.21 (paper - Pulvermuller)
***** problem with embodied only approach
******* the group level finding is usually not true for all indviduals in the same way
******* esp. Re. Lesionsi n sensorimotor areas, that should effect naming etc.
******* looking at indivdual patients, comparing them to control - not all of them are hurt in the same way
******* brain motor deficits are not always exhibited as naming deficit.
******* also the actual use of the tools is not really hurt so much.
***** various hubs
******* iFC:
                semantic vs phonological task with the same stimulus, found area in the iFC, then tested the same task with TMS
******* sTC:
                Wernicke's area - understanding
                Brocha - production
                conductance aphasia - can't repeat heard phrases, but can produce own, and can understand.
******* iPC:
                Compare non words to words of different categories
                there's significant activation in the angular gyrus in all categories, compared to non-words. That article suggests the angular gyrus is a hub of general semantic understanding
******* i&mTC:
******* pulvermuller says: too many centers to be called "hubs"
***** referrential learning: connecting between symbols and meanings
******* many intermediary areas, connections, between the sensory areas which are the so-called hubs.
******* through hebbian learning, the hubs associate between the different modalities
***** combinatorial semantics:
******* semantic categories from frequency of mutual occurrence of words
******* can build these categories without any grounded experience
*** 25.11.21 (mahon and caramazza)
***** meteyard et al. 2010 - review of embodiement
***** strong embodiement really does claim that all the information we have about a concept is encoded in sensory/motor cortex
***** problem with phonological analogy - the task is phonological, so it makes sense that the phonological attriburtes of the objects will interfere. We need a task that asks about the semantics itself, without reference to the phonology
***** there will be a bonus Q in the exam - find an experiment that refutes "grounding by interaction" it's so wide that it can include any experimental result
***** important paper for critical thinking
***** we want to always ask: *this conclusion makes sense, but is it the _only_ conclusion that makes sense?*
***** bottom lines of grounding by interaction:
******* concepts can be activated by sensory information, and this is the basis of the grounding of various, even abstract concepts
********* those concepts are *not* dependent on the sensory processing
******* they do create a substrate for concepts to "take form" on - "instantiate"
*** 2.12.21 (conceptual metaphor theory)
***** abstract knowledge relies on sensory metaphors
***** sensory experiences are like scaffolding on which we construct knowledge
***** our sensorimotor experiences, which are straightforward help us understand complex ideas
***** may not be relevant for familiar metaphors - for those we have learned a direct connection with the meaning (weak version of theory)
***** results/conclusions
:PROPERTIES:
:ID:       20220112T093607.072065
:END:
******* there is sensory activation while reading metaphors
******* no differential activation in language or other sensory areas
******* their results support a strong version of the conceptual metaphor theory
***** other papers:
******* in response to familiar and novel metaphors: the more familiar the metaphor the less sensory activation was found (supports the weak version of the theory)
******* metaphor understanding combines sensorimotor simulation and abstract lexical and semantic codes
***** abstract concepts:
******* mostly a challenge for embodied theories
******* less stable over time
******* more dependent on cultural, emotional and liguistic information
******* can be explained by statistical model (co-occurance), but these have a problem explaining grounding in reality - a circular definition of terms, since every term is defined just by relation to other terms
******* andrews et al. There are two semantic/knowledge systems: one based on experience (which relies more on sensorimotor information) and one more lexical, relying on connections between words in spoken language (distributional/co-occurrence)
******* binder et al. Abstract words activate more/other areas than concrete words
******* anagram task
********* same performance for concrete and abstract words ( so we can't say that brain activation was different  because of task load)
********* the more concrete the word, the more posterior the activation was
********* abstractization maybe involved with more frontal processing
******* this idea of frontal areas being more abstract was also found for things other than language! Like rules and goals.
********* badre and dqesposito, about rules
********* increasing complexity levels of rules governing the response to stimuli
***** interim course summary
******* concrete words can induce activations in sensory motor cortices, that are fast,   automatic and somatotopic
******* this was taken as evidence for embodied cognition - concept meainng is grounded in sensorimotor circuits & experiences (but see Mahon & Caramazza: this can be a byproduct, spillover activation, associations etc.)
******* metaphors can also induce similar activations (but: only novel?)
******* abstract terms seem less embodied - at least, have frontal activation which is missing from concrete concepts
***** towards a theory of abstract terms :
******* focus on mechanism rather than content - don't talk about specific areas of concepts (like emotions, or mathematics etc.) Look for a general explanation of abstractization
******* combine sensorimotor and linguistic processes - the answer is probably not only embodied or only abstract
******* make precise predictions about conceptual acquisition (=learning new concepts, especially abstract ones)
******* introspection might play a special role in understanding abstract concepts - my own episodic memory plays a role in understanding
******* address cross-linguistic differences in abstract concept representation (e.g time in mandarin is on a top-down axis)
******* generalize across types of abstract terms
*** 9.12.21 (relations between objects)
***** characteristics of relations:
******* require ‘relata’ - the objects of the relation
******* generalizable beyond instances (abstract)
******* categorical - relations are usually amongst things belonging to categories
******* structured (order matters)
***** "the mind is an association machine" - Kahaneman
***** Bar's model:
        we have have two stream of information processing:
          - low image frequencies - use to make preliminary guesses about what objects may be, and about context
          - high frequencies - slower, more precise, used to choose between the guesses we have
***
***** Green & Hommel paper:
******* relations between objects are part of the perceptual processing  - on a low level
******* the relations between objects are explicitly represented
******* the representation of object pairs are part of what mediates/connects between the visual system and higher cognitive systems
*******  perception is affected by function of objects (humphries & ridooch
):
                patients with neglect, when they are asked to find something in their visual field the do much better when it's described by the function that it does than by name or characteristics like color

                They are also better at recognizing objects that have "Better" affordance - like mugs with handles facing us
***** Green and Hummel:
******* show that interacting objects are recognized faster than non interacting and unrelated objects
******* claim this is due to the fact that interacting objects are perceived as a single unit - *this is about action between objects, not just association*
******* surprising result unrelated-interacting effect
******* word superiority effect: the char under fixation is recognized faster when it's a part of a whole word than when it's in some random stream of letters
********* the effect is seen in EEG in P1 (~150ms) so we know it's part of the perception process, rather than post-perception semantic processing
******* contradicting study: Gronau and Shachar: recognition of objects was better for related vs unrelated pairs, but there was no difference between pairs where there was an implied action between the objects, and pairs that were just related.
*** 23.12.21 - semantic unification
***** three basic functions of linguistic processing:
******* memory - lexicon of known words
******* unification *this is the focus of the paper*
******* control - which language to use, when to speak etc. How to use the language
***** unification: integrating a word meaning into unfolding context, constructive process.
***** integration: different sources of information activate stored representations
***** EEG correlates:
******* N400
********* marker for processes involved i n the integration of the meaning of a word into the overall semantic representation constructed for the preceding input
********* or.. Maybe it's just how hard it is to retrieve the meaning of a word (easier for congruent context)  - so it reflects the organization of (lexical) meaning in semantic memory
*********** the boy went out to fly "a" vs "an": so we already plan what word and article awe are going to retrieve, or it's surprise - but doesn't look like integration, since there's no word to integrate..
********* or.. reflects unification/integration processes and not only ease of retrieval - we see it happens simultaneously, we don't have to have an expectation set up
********* there's a difference between the hemispheres: in the left hemisphere we see a difference between within category and between categories (compared to expected), while in the R hemis we don't.
*********** RH: post-lexical unification
*********** LH: predictive semantic processing
********* it's adaptive: the context matters. If we move to a context where a peanut is animate, and can be in love - we get an N400 for a word that refers to it as inanimate.
******* P600
********* syntactic violations
********* also when the sentence "doesn't compile" like "every morning the eggs would eat.."
********* more about combinatorial aspects of the language "what goes with what"
******* N400/P600: two different streams? Semantic/combinatorial
*** 30.12.21 (relations berween concepts)
***** next week room 214 sharet bdg
***** intensive (intention) definition vs extensive:
******* intension: the formal definition, the content of a general idea
******* extension: the instantiation or examples of things belonging to that definition
******* we usually learn the extension first, at least when we're young, through experience, and later we generalize
******* we always have  חריגות from the rules we find - so we get to thinking about these extensions in a probablistic way
***** associations are different from relations - they don't have the trasisitivity, or structure we want from relations: if A reminds me of B and B reminds me of C, that doesn't meant that A reminds me of C.
***** TODO READ: Kruschke on baysian thinking(!)
[[/mnt/g/My Drive/.notes.v2/slip-box/20211014101632-class_notes_semantic_integration_1071493301.org_20211230_104221_mHuvYb.png]]
***** we have priors, we collect evidence and create a posterior, and that serves as our new prior.
***** this relates to the connection between context and perception. The context is our prior
***** we can always question the assumptions of the authors of the paper! (Not just the dat and their inference)
***** main characteristics of relations:
******* structure-consistent mapping
******* compositionallity
                Constituent entities retain their original identity and meaning
******* systematicity
             A concept retains some of its attributes - which are whhat makes it behave a certain way in relations that it's a part of. SO we know something about how that object will behave in other relations that we don't know yet: we can generate new relations/proposition s
***** we can describe relations w/ regard to how many places they contain (how many objects are in relation)
- conceptual chunking
    - recoding of concepts into fewer dimensions
    - c a t a h t n i a
- segmentation
    - new entity
    - internal relations are lost external relations can be formed

***** they say that when we ask people to compare situations they instinctly look for structural similarities between the relations present (which does't happen when ther's no comparison request)
***** "language is an invitation to generalize"
*** baron and osherson
In this study the authors aim to test the way the meaning of a concept is constructed from the meaning of other concepts.
They use images to evoke different concepts in the mind of subjects while they undergo an fMRI scan, and check the correlation of the activation when a given concept is being represented with a combination of the activation of what they denote as its constituent concept (e.g compare boy to man + child).
They do this with both addition and multiplication, and suggest that multiplication is a more natural operation to expect for this function. They also compare the correlation with the correct pair of concepts (correct CC) and with incorrect pairs (spurious CCs).
They find that in the lATL, and to some degree in the PCC as well, there are voxels that are better correlated with multiplication than with addition. They conclude that the lATL is involved in this type of construction of meaning.

I enjoyed the paper and I think that the idea of meaning being constructed in this way is interesting - it reminded me of the way current NLP algorithms work: they represent words as vectors in some high dimentional space constructed in some manner which I don't remember, but in which semantics behave exactly they way that the authors expect. For example, if you take the representation for "queen" and detract "woman", you'll get "king".
I thought that the way they chose to test it was original, but I did have some reservations.
When they acquire the data, if I understood correctly, they use the combined (averaged?) activation for some of the pairs to denote new concepts - e.g "adult" is taken from "man" and "woman" and "male" is taken from "man" and "boy", and they later use this as the basis for their comparisons: they check whether "boy = child + male" (this is from the paper). But this is a strong assumption (almost assuming what they are trying to show) - that the mutual activation of "man" and "boy" is equal to the idea of "male".
Another matter is the significance threshold in their analysis. After shuffling lables to find the threshold, they found it be 4/12, and I thought that was a little strange - it means that a voxel where all concepts were better correlated with their correct CC than with one of their spurious CC, but less well correlated with it than with both other spurious ones would still be significant, and that doesn't really convince me in a common sense sort of way.
I'm also not totally convinced by the assumtion that multiplication is more suited than addition: when the two concepts arise as part of a network of associations, and especially if they arise in an implicit way as they do here, I don't see why we should expect a linear relationship at all, let alone an additive one.
Last, there are many combinations of concepts that we can consider as "constituent" to a given concept, and who's to say that this specific representation matches the one each subject has.
*** Home exam:
:PROPERTIES:
:ID:       20220105T160809.433213
:END:
