:PROPERTIES:
:ID:       20210627T195317.106894
:ROAM_REFS: cite:ERPDecodingPresentation
:END:
#+TITLE: Notes on Presentation about Decoding of information from EEG Oscillations
#+ROAM_KEY::PROPERTIES:
:Custom_ID: ERPDecodingPresentation
:NOTER_DOCUMENT: //home/jonathan/google_drive/.notes/.bibliography/bibtex_pdf/Decoding_Part1_June_29_2020.pdf
:AUTHOR: Bae, G. & Luck, S. J.
:JOURNAL:
:DATE:
:YEAR: 2018
:DOI:
:URL:
:END:

* Notes
:PROPERTIES:
:NOTER_DOCUMENT: /mnt/c/Users/Jonathan/Google Drive/.notes/literature-notes/Decoding_Part1_June_29_2020.org
:END:

*** essentialy - running an SVM classifier on scalp distributions (=ERPs from all electrodes at a given time point) to classify (e.g.) positive from negative images, recognition of specific faces etc.
*** train a classifier per subject  - doesn't assume the same scalp distribution for all subjects.
*** train a classifier from every time point in the data.
*** many many classifiers are possible this way - also possible to plot the change in accuracy with data from different times along the neuronal response.
*** for every subject, show 44 images, 22 positive, 22 negative, show each image 30 times (is this correct?)
*** divide the 30 trials per image into 3 random sets of 10, and average them (to eliminate noise, like in a regular ERP nalysis)
*** use the averages as train (2 sets) and test (1 remaining set)
*** repeat the random division three times (per image), for cross validation
*** compute the classifier's performance (% correct predictions)
*** classifying in N-dimensional space (N = # of electrodes) allows for greater possible separation between data points (explain why?)
***** as an intuition - it means we can consider more aspects of the objects being classified at the same time.
*** for multiclass classification - use N x "1 vs all" classifiers (N = # of possible classes)
*** Limitations:
***** doesn't give information about single trials, i.e. can't correlate with behavior
***** accuracy not very high
***** no correlation between accuracy and subject performance (probably due to significant differences in cortical structure ("geometry") between subjects)
*** differences from "engineering"-oriented ML/classifiers:
***** we care about underlying reasons for classification, not just (even more than-) decoding accuracy. (maybe consider a more informative classifier such as decision trees?)
***** even fairly inaccurate classifications can be informative - because we only need to be better than chance (but can we rely on them? what's the pvalue?)
***** we don't need the classifier to be so good that it will be accurate over time (i.e. more sessions with the same subject), since we usually run a single session and analyze only that. (I think that it may be worth the effort to make better predictors for the ability to make more complex experiments)
***** not important to be able to decode a single trial (vs the 10 trial average described here), unlike real-time brain-computer interfaces applications.
*** case study: predicting orientation of an arrow that subjects view (16 discreet directions)
***** fMRI shows a difference, maybe EEG can too?
***** could've used traditional statistics (e.g. ANOVA) but that would've  demanded that the scalp distribution would be the same across subjects (I think he could've used a statistical test on a per subject basis in the same way he would later use the SVM, but maybe the dimensionality would've been too high)
*** confusion matrix: the probability the classifier gave for every classification possibility vs the ground truth. plotted as a 2-D heat map, we would like the diagonal (i.e. the probability the classifier gave to the right class) to be with high probability, and the rest with very low probability.
*** examples of things they managed to decode:

- direction and position of arrow (separately and in combination)
- emotion and identity of faces (separately and in combination)
- letters
- positive and negative valence of images

*** What is decoding good for? advantages/disadvantages:
***** if we can decode the stimulus from the signal it give us more confidence that the signal actually represents the stimulus in some way, that it contains *information* about the stimulus.
***** traditional methods say something about how brain activity changes under different conditions (hopefully the delta represents an actual component's activity - but we can't be sure)
***** it requires minimal assumptions about the ERP components behind the effect:

(to me it looks like this is because it also doesn't guarantee anything about specific components, but only about the signal as a whole)

***** we're losing information about which process is actually being decoded, e.g. - if there are several mental processes involved in the task, we'll get several time periods of high accuracy prediction, but they may belong to different processes.
******* or even the motor response to the task.
***** it's particularly useful for detecting a pattern of activity across all electrodes, every electrode is a feature (per time-point)
******* as above - the pattern may represent the difference between conditions better than any single electrode site.
***** often better power (= effect size) than difference waves
***** more sensitive to noise than tradtional approach (why?)
*** the "above chance" measure just means that there is some (non zero) correlation between brain activity and (somehing in) the stimulus. may not be what we think of as "the stimulus" (e.g. hair color instead of the actual identity of the face)
